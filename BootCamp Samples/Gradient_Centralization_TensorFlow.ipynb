{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IieqPex4O3eJ"
      },
      "source": [
        "# GCTF MNIST\n",
        "\n",
        "This notebook shows the the process of using the [`gradient-centralization-tf`](https://github.com/Rishit-dagli/Gradient-Centralization-TensorFlow) Python package to train on the [Fashion MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist) dataset availaible from [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets).Gradient Centralization is a simple and effective optimization technique for Deep Neural Networks as suggested by Yong et al. in the paper \n",
        "[Gradient Centralization: A New Optimization Technique for Deep Neural Networks](https://arxiv.org/abs/2004.01461). It can both speedup training \n",
        " process and improve the final generalization performance of DNNs.\n",
        "\n",
        "## A bit about GC\n",
        "\n",
        "Gradient Centralization operates directly on gradients by centralizing the gradient vectors to have zero mean. It can both speedup training process and improve the final generalization performance of DNNs. Here is an Illustration of the GC operation on gradient matrix/tensor of weights in the fully-connected layer (left) and convolutional layer (right). GC computes the column/slice mean of gradient matrix/tensor and centralizes each column/slice to have zero mean.\n",
        "\n",
        "![](https://i.imgur.com/KitoO8J.png)\n",
        "\n",
        "GC can be viewed as a projected gradient descent method with a constrained loss function. The geometrical interpretation of GC. The gradient is projected on a hyperplane $e^T(w-w^t)=0$, where the projected gradient is used to update the weight.\n",
        "\n",
        "![](https://i.imgur.com/ekHhQv0.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcpkfjkwSjmv"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjTQqCEaTSSG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from time import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32NuQrDdSpP3"
      },
      "source": [
        "### Install the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFvPquvcOq1B",
        "outputId": "781fefd8-1b38-4c20-f9a8-efa9d954cccb"
      },
      "source": [
        "!pip install gradient-centralization-tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradient-centralization-tf\n",
            "  Downloading gradient_centralization_tf-0.0.3-py3-none-any.whl (10 kB)\n",
            "Collecting keras~=2.4.0\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from gradient-centralization-tf) (2.9.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras~=2.4.0->gradient-centralization-tf) (1.7.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras~=2.4.0->gradient-centralization-tf) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras~=2.4.0->gradient-centralization-tf) (6.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras~=2.4.0->gradient-centralization-tf) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (1.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (2.9.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (21.3)\n",
            "Collecting tensorflow>=2.2.0\n",
            "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 6.4 kB/s \n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (0.27.0)\n",
            "Collecting tensorflow>=2.2.0\n",
            "  Downloading tensorflow-2.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 29 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 18 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.8 MB 31 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.7 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 4.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (3.19.6)\n",
            "  Downloading tensorflow-2.8.4-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.9 MB 4.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (0.4.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (2.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (4.1.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->gradient-centralization-tf) (1.15.0)\n",
            "Collecting tensorflow>=2.2.0\n",
            "  Downloading tensorflow-2.8.3-cp37-cp37m-manylinux2010_x86_64.whl (497.9 MB)\n",
            "\u001b[K     |█████████████████████████████▏  | 454.5 MB 1.2 MB/s eta 0:00:37"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okru2B3uTKRx"
      },
      "source": [
        "## Get the data and create model structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywUm1ZYiOY8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630d7bff-15a4-487c-84c9-3c96bea42912"
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Model architecture\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p_jknUHUILI"
      },
      "source": [
        "## Train a model without `gctf`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Us9_ZCBpD2a"
      },
      "source": [
        "Make a Callback to compute computation time\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADdFS7OapCXZ"
      },
      "source": [
        "class TimeHistory(tf.keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time() - self.epoch_time_start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQXmGp4_Oj7l",
        "outputId": "407f4d3f-c422-439d-e26b-74eb90edf373"
      },
      "source": [
        "time_callback_no_gctf = TimeHistory()\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history_no_gctf = model.fit(training_images, training_labels, epochs=5, callbacks = [time_callback_no_gctf])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 2ms/step - loss: 0.6533 - accuracy: 0.7619\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3986 - accuracy: 0.8559\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3527 - accuracy: 0.8731\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3271 - accuracy: 0.8810\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3075 - accuracy: 0.8884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_qW351shXgM"
      },
      "source": [
        "## Train a model with `gctf`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slHbE9hKWBWV",
        "outputId": "cfed8cb2-6260-4303-e749-ac1a71143949"
      },
      "source": [
        "import gctf #import gctf\n",
        "\n",
        "time_callback_gctf = TimeHistory()\n",
        "\n",
        "model.compile(optimizer = gctf.optimizers.adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_gctf = model.fit(training_images, training_labels, epochs=5, callbacks=[time_callback_gctf])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2572 - accuracy: 0.9063\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2551 - accuracy: 0.9103\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2330 - accuracy: 0.9133\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2288 - accuracy: 0.9168\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2237 - accuracy: 0.9165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhfeOw1FgLPE"
      },
      "source": [
        "## Compare results\n",
        "\n",
        "In this example we are further interested in also comparing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-PfvMpCdhm6",
        "outputId": "16ed65f5-d958-45cc-bd61-c09dcd6e9c1d"
      },
      "source": [
        "#Compare Results\n",
        "from tabulate import tabulate\n",
        "\n",
        "data = [[\"Model without gctf:\",sum(time_callback_no_gctf.times),history_no_gctf.history['accuracy'][-1],history_no_gctf.history['loss'][-1]],\n",
        "        [\"Model with gctf\",sum(time_callback_gctf.times),history_gctf.history['accuracy'][-1],history_gctf.history['loss'][-1]]] \n",
        "\n",
        "print(tabulate(data, headers=[\"Type\",\"Execution time\", \"Accuracy\", \"Loss\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type                   Execution time    Accuracy      Loss\n",
            "-------------------  ----------------  ----------  --------\n",
            "Model without gctf:            20.183    0.887617  0.310299\n",
            "Model with gctf                18.464    0.916467  0.22555\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}